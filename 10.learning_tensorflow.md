# learn the course of the MOOC

Course address https://www.icourse163.org/learn/PKU-1002536002?tid=1003797005#/learn/content?type=detail&id=1005355442

## install tensorflow in jetson tx2 for jetpack 4.2+python3.6

first method

$ pip3 install --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v42 tensorflow-gpu==1.13.1+nv19.5 --user

second method

$ wget https://developer.download.nvidia.cn/compute/redist/jp/v42/tensorflow-gpu/tensorflow_gpu-1.13.1+nv19.5-cp36-cp36m-linux_aarch64.whl

$ pip3 install --index https://pypi.mirrors.ustc.edu.cn/simple/ PATH_OF_THE_FILE/tensorflow_gpu-1.13.1+nv19.5-cp36-cp36m-linux_aarch64.whl

!!!If you meet error when installing h5py, please run this command to solve the dependency:

$ sudo apt-get install libhdf5-serial-dev hdf5-tools

## Defination of machine learning

如果一个程序可在任务T上，随着经验E的增加，效果P随之增加， 则这个程序可以从经验中学习

## 张量

就是多维数组（列表）

阶：张量的维数

## 基本函数

tf.shape(a) 返回a的维度信息，

tf.nn.bias_add(乘加和，bias) 将bias加入乘加和

tf.reshape(tensor,[n,m]) 将tensor变成需要的维度，如有-1表跟随另一个值自动计算

tf.split(切谁，怎么切，哪个维度切)

tf.concat(值，在哪个维度) 将t1和t2在 哪个维度上拼接

tf.variable_scope(name)

## 计算图（Graph）

搭建神经网络的计算过程，只搭建，不运算

只描述运算过程，不计算结果

## 会话（Session）

执行计算图中的节点运算

## 参数

 即神经元上和权重矩阵

## 神经网络实现过程

准备数据集，提取特征，作为输入喂给神经网络

搭建NN结构，从输入到输出（先搭建计算图，再用会话执行，前向传播）,使用session.run()时，先将变量初始化，可用tf.global_variables_initializer() 初始化, tf.placeholder() 占位， 定义输入和输出，及各层神经网络和参数

大量特征数据喂给NN， 迭代优化参数（后向传播），损失函数减小， 可用函数tf.train.GradientDescentOptimizer(learning_rate).minimize(loss),  或者 MomentumOptimizer(learning_rate).minimize(loss), 或者 AdamOptimizer(learning_rate).minimize(loss)，定义损失函数和反向传播方法

使用训练好的模型预测和分类

##  神经网络优化

### 激活函数(activation function)

增加网络的区分度，引入非线性

用得较多的：tf.nn.relu() tf.nn.sigmoid() tf.nn.tanh()

层数=隐藏层的层数+1个输出层（输入层无计算功能，不计入）

总参数=总权重+总偏移

输出层不过激活函数

### 优化方向：损失函数loss、学习率learning_rate、滑动平均ema、正刚化regularization

loss函数: Mean squared Error, Cross Entropy（两个概率分布之间的距离）, 自定义

Mean squared Error : tf.reduce_mean(tf.square(计算值-真值)) 

Cross Entropy: -tf.reduce_mean(真值*tf.log(tf.clip_by_value(y,min计算值,max计算值))) 

softmax()：使得n分类的n个输出满足概率分布，用法如下(y为计算值，y_为真值)：
> ce = tf.nn.sparse_sotfmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_,1))
> cem = tf.reduce_mean(ce)

Learning_rate: 每次参数更新的幅度
> w(n+1) = w(n) - learning_rate * grad(loss)
> 大了会出现振荡不收敛，小了收敛太慢
> 指数衰减学习率
>> learning_rate = LEARNING_RATE_BASE * LEARNING_RATE_DECAY **(global_step/learning_rate_step)
>>>learning_rate_step=总样本数/BATCH_SIZE 即多少轮更新一次学习率
>>> global_step = tf.Variable(0,trainable=False) //仅用于计数，不是训练参数，令trainable=False
>>> learning_rate =  tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, LEARNING_RATE_STEP, LEARNING_RATE_DECAY, staircase = True) //staircase为true时，global_step/learning_rate_step取整数，学习率为阶梯衰减，否则为平滑曲线衰减

滑动平均（影子值）
> 记录了每个参数一段时间内过往值的平均，增加了模型的泛化性
> 针对所有参数，就像给参数加了影子，参数变化，影子缓慢
> 影子 =   衰减率 * 影子 + （1 - 衰减率）* 参数 
>> 影子初值=参数初值
>> 衰减率=min{MOVING_AVERAGE_DECAY，(1+轮数)/(10+轮)}
>>> ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, gobal_step)
>>> ema_op = ema.apply(tf.trainable_variables()) //每次运行，所有待优化参数求滑动平均
>>> with tf.control_dependencies([train_step,ema_op])://将计算ema和训练过程合成为一个节点
>>>     train_op = tf.no_op(name='train')
>>>  ema.average(参数名) //查看某参数的滑动平均值

正则化缓和过拟合
> 过拟合：对已经训练过的数据预测精度高，但从未见过的数据预测结果不准确
> 正则化：在损失函数中引入模型复杂度指标，利用给W加权值，弱化训练数据噪声（一般不正则化b）
>> Loss = loss(计算值与真值) + REGULARIZER * loss(w)//用REGULARIZER超参数给出w在总loss中的比例，即正则化的权
>>> loss(w)有两种求法：
>>> tf.contrib.layers.l1_regularizer(REGULARIZER)(loss)//所有w的绝对值求和
>>> tf.contrib.layers.l2_regularizer(REGULARIZER)(loss)//所有w平方求和
>> 计算好loss(w)后，要用tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(REGULARIZER)(loss))把计算的值放入集合中
>> 再用loss=cem+tf.add_n(tf.get_collection('losses'))将集合加入原loss函数，构成新的loss函数

## 图形可视化模块(matplotlib)

需要安装 sudo pip3 install matplotlib.pyplot
使用方法：
> import matplotlib.pyplot as plt
> plt.scatter(x,y,c='coloer')
> plt.show()
> xx,yy = np.mgrid[起:止:步长,起:止:步长]
> grid = np.c_[xx.ravel(),yy.reval()]//生成矩阵
> probs = sess.run(y,feed_dict={x:grid})
> probs = probs.reshape(xx.shape)
> plt.contour(x轴坐标值,y轴坐标值,该点的高度,levels=[等高线的高度])
> plt.show()


## TIPS
tf.get_collection("")   从集合中取全部变量，生成一个列表

tf.add_n([])    列表内对应元素相加

tf.cast(x,dtype)    把x转为dtype类型

tf.argmax(x,axis)   返回axis维度中，最大值所在索引号

os.path.join("home","name") 返回home/name

字符串.split()

with tf.Graph().as_default() as g:  其内定义的节点在计算图g中，用于复现已经定义好的神经网络

## 对于模型的操作

保存模型：
-  每运行一定轮数的训练，保存一次模型
- **saver = tf.train.Saver()** //实例化saver对象
- with tf.Session() as sess:
-   xxx.....
-   **saver.save(sess,os.path.join(MODEL_SAVE_PATH,MODE_NAME),global_step=global_step)**
-   xxx.....

加载模型：
- with tf.Session() as sess:
-    **ckpt=tf.train.get_checkpoint_state(MODEL_PATH)**
-    **if ckpt and ckpt.model_checkpoint_path:**
-    **saver.restore(sess,ckpt.model_checkpoint_path)**

实例化可还原滑动平均值的saver
- 此时会把滑动平均值作为赋值给模型中的对应参数
- ema = tf.train.ExponentiaMovingAverage(滑动平均基数)
- ema_restore = ema.variables_to_restore()
- saver = tf.train.Saver(ema_restore)

准确率计算方法
- correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))
- accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)


## 模型测试

def test(mnist):
    with tf.Graph().as_default() as g:
        定义 x y_ y
        实例化可还原滑动平均值的saver
        计算正确率
        while True:
            with tf.Session() as sess:
                #加载ckpt模型
                 实例化加载模块
                 判断ckpt模型是否存在
                    恢复会话
                    恢复轮数
                    计算准确率
                    输出结果
                如果没有模型：
                    给出提示
                    return

def main():
    mnist = input_data.read_data_sets("./data/",one_hot=True)
    test(mnist)
    
if __name__== '__main__':
    main()


## tfrecords

tfrecords是一种二进制文件，可先将图片和标签制作成此格式文件，再用tfrecords读取可提高内存利用率

用tf.train.Example协议存储训练数据，训练数据的特征用键值对形式表示，如'img_raw':值 'label':值 值是 Byteslist/FloatList/Int64List

用SerializeToString()把数据序列化成字符串存储

> 生成tfrecords文件：
> writer=tf.python_io.TFRecordWriter(tfRecordName) #新建一个writer对象
> for  循环遍历每张图和标签:
>   example=tf.train.Example(features=tf.train.Features(feature={
>       'img_raw':tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),'label':tf.train.F
>       eature(int64_list=tf.train.Int64List(value=labels))})) #把每张图都装到example中
>   writer.write(example.SerializeToString()) #序列化example
> writer.close()

> 解析tfrecords文件：
> filename_queue=tf.train.string_input_producer([tfRecord_path])
> reader=tf.TFRecordReader() #新建一个Reader对象
> _,serialized_example=reader.read(filename_queue)
> features=tf.parse_single_example(serialized_example,features={'img_raw':tf.FixedLenFeature([],tf.string),'label':tf.FixedLenFeature([10],tf.int64)})
> img=tf.decode_raw(features['img_raw'],tf.uint8)
> img.set_shape([784])
> img=tf.cast(img,tf.float32)*(1./255)
> lable=tf.cast(features['label'],tf.float32)


## 数据批获取

> coord =tf.train.Coordinator()
> threads=tf.train.start_queue_runners(sess=sess,coord=coord)
>  批获取操作
>coord.request_stop()
>coord.join(threads)



##  卷积神经网络

主要有两个部分组成：高层抽象特征， 精减特征点（卷积、激活、池化）+全连接网络

### 卷积
不填充 padding='VALID' 输出图片边长=（输入图片连长-卷积核长+1）/步长  （向上取整）

padding(全零填充) 时 （padding='SAME'）输出图片边长=入长/步长   （向上取整）

tf.nn.conv2d(
    输入描述，    [batch,5,5,1]  一次喂入batch张图，每张图5*5分辨率，1个通道  （灰度图1个通道，彩色图3个通道）
    卷积核描述，    [3，3，1，16]   3*3  ， 1个通道（应该与输入的通道相等） ，16个核（卷积操作后，输出深度为16，即输出为16通道）
    核滑动步长，    [1，1，1，1]  中间两个分别为行步长和列步长，第1个和第4个参数都固定为1
    padding=' VALID'
)

输出值与输入描述类型一致

### 池化(Pooling)

用于减少特征数量：最大值池化可提取图片纹理，均值池化可保留背景特征

pool=tf.nn.max_pool(输入描述，池化核描述[1,2,2,1](仅描述大小，第2，3个参数分别为行列分辨率，第1，4个参数固定是1)，池化核滑动步长，padding='SAME')
pool=tf.nn.avg_pool()


### 舍弃(Dropout)

在神经网络训练中，将一部分神经元按照一定概率从神经网络中暂时舍弃。但使用时，会恢复被舍弃的神经元链接

有效抑制过拟合，一般用在全连接网络中

tf.nn.dropout(上层输出，暂时舍弃的概率)

if train: 输出=tf.nn.dropout(上层输出，舍弃概率)



### 数据预处理

数据集不够大时，可以做数据预处理：
- 图像旋转
- 图像缩放
- 对图像增加噪音
- 对图像进行模糊
-  将图像往x、y方向上按指定数量移动图像像素

数据倾斜矫正：
-  先边缘轮廓检测
- 霍夫曼倾斜校正算法（检测图中直线、计算直线倾斜信息再校正）

去横线：
- leptonica库（去掉横线，再用函数补出擦除的部分）

文本区域定位：
- 基于MSER算法改进（先将过大或过小的矩形筛掉，再将大和小的交叠部分将小的矩形筛除--并不是纯去掉，而是将小的合成大的，最后得出边框）

CTC损失函数


人脸数据集：  Microsoft fer2013 plus
预处理好的数据：https://pan.baidu.com/s/1HkNil1Rl1ABTKGPpNJw6lw    r921

LeNet

RESNET-50 CNN提取图像特征
VGG16模型

 梯度消失、对抗损失、对抗损失
 
 实时目标检测数据集： MS COCO VOC07
 
 自动上色： nico-opendata数据集（不好），danbooru2017 (泛化不好)

AI challenger数据集：  中文描述数据集


t-SNE特征聚类可视化：将高维数据降维到低维空间

## 强化学习
Q-learning算法
